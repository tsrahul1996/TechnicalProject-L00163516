{"cells":[{"cell_type":"markdown","source":["# Technical Project : NIH Chest X-ray Analysis and Disease Detection\n\n##Goals\n1.   Infiltration is the most common disease among the 14 diseases.\n2.   People of age 50 to 60 have a greater chance of getting diseases like Cardiomegaly, Infiltration and Pneumonia\n3.   Predict the disease of a person from the respective X-ray using deep learning\nmodels.\n\n\n##1. Data Aggregation \n\nThere are mainly two files to consider, The first one is image files which contain chest X-rays of 112,120 samples. The second one is a CSV file that provides patient\nrecords and corresponding disease labels for the full dataset. There will be a total of 15 classes that consist of 14 diseases plus ’No findings’. The dataset can be accessed\nfrom the official website of NIH (Summers 2017)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d5fd819c-0d20-43ac-8a1f-8fb23a9b0b90"}}},{"cell_type":"markdown","source":["##Goals 1"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c9860ddc-0b3e-488a-835a-1ff987ceea44"}}},{"cell_type":"markdown","source":["###Csv dataset"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e8bed58-db28-4af7-a365-2664cbe6e60e"}}},{"cell_type":"markdown","source":["The first step is to load the csv file which is downloaded to the dbfs (Databricks Filesystem) to a spark dataframe."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"961beb4d-0f98-4ca8-ab4a-02ede3d529c7"}}},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, TimestampType\n\ndf = (sqlContext.read.format(\"csv\").\n  option(\"header\", \"true\").\n  option(\"nullValue\", \"NA\").\n  option(\"inferSchema\", True).\n  option(\"encoding\", \"UTF-8\").  \n  option(\"ignoreLeadingWhiteSpace\", True).\n  option(\"ignoreTrailingWhiteSpace\", True).\n  option(\"multiLine\", True).\n  load(\"/FileStore/tables/Data_Entry_2017.csv\"))\n\ndf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"03c00df8-b6b3-4ca1-8d42-9c094d30cdda"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Next step is to import nessasry libraries"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca9cb98e-806f-4d25-8bf1-8df5010464ac"}}},{"cell_type":"code","source":["import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom glob import glob\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom pyspark.sql.functions import col, countDistinct"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1109f91-6285-4270-9877-cae47bc95874"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##2. Data Transformation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"39d10a4a-a3fb-498f-8603-65b84e56e110"}}},{"cell_type":"code","source":["display(df.limit(7))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5669b943-5c73-419e-a4be-4d53d897b067"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Check columns names and convert them to simple format"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"76140e82-38b6-4cf8-b1d7-e755f34003df"}}},{"cell_type":"code","source":["df = df.withColumnRenamed(\"Image Index\", \"imageIndex\")\\\n       .withColumnRenamed(\"Finding Labels\", \"labels\")\\\n       .withColumnRenamed(\"Follow-up #\", \"followUp\")\\\n       .withColumnRenamed(\"Patient Age\", \"age\")\\\n       .withColumnRenamed(\"Patient ID\", \"id\")\\\n       .withColumnRenamed(\"Patient Age\", \"age\")\\\n       .withColumnRenamed(\"Patient Gender\", \"gender\")\\\n       .withColumnRenamed(\"View Position\", \"viewPosition\")\\\n       .withColumnRenamed(\"OriginalImage[Width\", \"width\")\\\n       .withColumnRenamed(\"Height]\", \"height\")\\\n       .withColumnRenamed(\"OriginalImagePixelSpacing[x\", \"imagePixelSpacingX\")\\\n       .withColumnRenamed(\"y]\", \"imagePixelSpacingY\")\\\n       .withColumnRenamed(\"_c11\", \"c11\")\n\ndf.show()\ndf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d44e63fc-fded-4637-8d77-6ad4390d0893"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"03feb360-9662-4fd6-88f8-bacfd55b6253"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["It was observed that one column constist of null values and it is not required."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66906258-1b8e-4b0c-848a-26b766dec315"}}},{"cell_type":"code","source":["df.filter(\"c11 is NULL\").count() #112120\ndf = df.drop('c11') #droping column with null values\ndf.show(n=2)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"59c57cf0-4c7f-424a-b9ef-27aeddcecf18"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Filtering out outliers \ndf = df.filter(df.age<100)\ndf.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85c0d22a-5ede-4e21-a569-89072df8621d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Here we take the labels and make them into a more clear format. The primary step is to see the distribution of findings and then to convert them to simple binary labels"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f1c755de-19c5-454e-9d42-36b768c3443b"}}},{"cell_type":"markdown","source":["## 3.Descriptive Analytics"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9e00c1b-04cc-4e17-add8-5f6d7cf35c36"}}},{"cell_type":"markdown","source":["we can plot the dataset in graph for finding the distribution"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a23a439-2023-47f9-ac0b-c3ce8a34a89e"}}},{"cell_type":"code","source":["#For graph reprasentation we are converting to pandas df.\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\npdf = df.toPandas()\nlabel_counts = pdf['labels'].value_counts()[:15]\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"22abe4c1-cc9f-463b-86bd-b6a7af37ef95"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We are perfoming one hot encoding as a part of data transformation. The features which are diseases in this case, are extracted from labels column and seperated to form another columns own its own. 0 and 1 are used to represent if the patient has disease or not."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"54e7ed9f-085a-445f-8e91-38884bbc7cd7"}}},{"cell_type":"code","source":["#similarly we can do this on spark dataframe by using udf function\nall_labels = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n\nfor c_label in all_labels: #loop the values\n    if len(c_label)>1: # leave out empty labels\n        oneHotEncoding = udf(lambda row: 1.0 if c_label in row else 0.0, DoubleType())  #udf to perform one Hot Encoding\n        df = df.withColumn(c_label, oneHotEncoding('labels')) #adding new columns using withColumn fn\n        df.count()\ndisplay(df.limit(7))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5003ac78-4473-40f5-a915-32620a556557"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["pdf['labels'] = pdf['labels'].map(lambda x: x.replace('No Finding', ''))\nfrom itertools import chain\nall_labels = np.unique(list(chain(*pdf['labels'].map(lambda x: x.split('|')).tolist())))\nall_labels = [x for x in all_labels if len(x)>0]\nprint('All Labels ({}): {}'.format(len(all_labels), all_labels))\nfor c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        pdf[c_label] = pdf['labels'].map(lambda finding: 1.0 if c_label in finding else 0)\npdf.sample(2)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a944543e-1aeb-47e5-9038-db4c4ae20a2d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Since we have too many categories, we can prune a few out by taking the ones with only a few examples"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0a453b23-a79f-48f8-80ae-5f50b3d400c6"}}},{"cell_type":"code","source":["# keep at least 1000 cases\nMIN_CASES = 1000\nall_labels = [c_label for c_label in all_labels if pdf[c_label].sum()>MIN_CASES]\nprint('Clean Labels ({})'.format(len(all_labels)), \n      [(c_label,int(pdf[c_label].sum())) for c_label in all_labels])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bd31bafb-ccdf-41a2-82b2-694a10eeaee5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##4.Data Visualisation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e61e178a-d2ad-460b-92f2-ff12db2710a3"}}},{"cell_type":"code","source":["# since the dataset is very unbiased, we can resample it to be a more reasonable collection\n# weight is 0.1 + number of findings\nsample_weights = pdf['labels'].map(lambda x: len(x.split('|')) if len(x)>0 else 0).values + 4e-2\nsample_weights /= sample_weights.sum()\npdf = pdf.sample(40000, weights=sample_weights)\n\nlabel_counts = pdf['labels'].value_counts()[:15]\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n\nax1.set_xticks(np.arange(len(label_counts))+0.5)\nax1.set_title('Count of Diseases in Patient Group')\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a8fe6334-841c-47b1-b375-4a10c4c5b5a0"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#normalization is performed on  label count to get a clearer graph\nlabel_counts = 100*np.mean(pdf[all_labels].values,0)\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\nax1.set_xticklabels(all_labels, rotation = 90)\nax1.set_title('Adjusted Frequency of Diseases in Patient Group')\n_ = ax1.set_ylabel('Frequency (%)')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"16a999db-15e6-4e59-8ed2-427ae5600326"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["By inferring the above graph we can conclude that Infiltration is the most common disease which has the highest frequency of diseases in patient group\n\nSo our hypothesis, Infiltration is the most common disease among the 14 diseases is true."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"04360ddf-cd7f-4930-9817-5c66cb7b61d7"}}},{"cell_type":"markdown","source":["##GOAL 2\n##1. Data Aggregation \n\nThe data loading part is same as goal 1 and we can use the dataframe from goal 1 to perform descriptive analysis."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"852d095a-6e05-4747-96b5-acd8d79f1352"}}},{"cell_type":"markdown","source":["##2. Data Transformation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"da9ce8dd-4186-4a2d-aeed-eb9baff19c49"}}},{"cell_type":"code","source":["from pyspark.sql.types import *\nmySchema = StructType([ StructField(\"imageIndex\", StringType(), True)\\\n                       ,StructField(\"labels\", StringType(), True)\\\n                       ,StructField(\"followUp\", IntegerType(), True)\\\n                       ,StructField(\"id\", IntegerType(), True)\\\n                       ,StructField(\"age\", IntegerType(), True)\\\n                       ,StructField(\"gender\", StringType(), True)\\\n                       ,StructField(\"viewPosition\", StringType(), True)\\\n                       ,StructField(\"width\", DoubleType(), True)\\\n                       ,StructField(\"height\", DoubleType(), True)\\\n                       ,StructField(\"imagePixelSpacingX\", DoubleType(), True)\\\n                       ,StructField(\"imagePixelSpacingY\", DoubleType(), True)\\\n                       ,StructField(\"Atelectasis\", IntegerType(), True)\\\n                       ,StructField(\"Cardiomegaly\", IntegerType(), True)\\\n                       ,StructField(\"Consolidation\", IntegerType(), True)\\\n                       ,StructField(\"Edema\", IntegerType(), True)\\\n                       ,StructField(\"Effusion\", IntegerType(), True)\\\n                       ,StructField(\"Emphysema\", IntegerType(), True)\\\n                       ,StructField(\"Fibrosis\", IntegerType(), True)\\\n                       ,StructField(\"Hernia\", IntegerType(), True)\\\n                       ,StructField(\"Infiltration\", IntegerType(), True)\\\n                       ,StructField(\"Mass\", IntegerType(), True)\\\n                       ,StructField(\"Nodule\", IntegerType(), True)\\\n                       ,StructField(\"Pleural_Thickening\", IntegerType(), True)\\\n                       ,StructField(\"Pneumonia\", IntegerType(), True)\\\n                       ,StructField(\"Pneumothorax\", IntegerType(), True)])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bde3a1b5-65a4-4d49-9725-af476c3c6572"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#we can create spark dataframe from pandas dataframe using createDataFrame which requires schema\nsdf = spark.createDataFrame(pdf,schema=mySchema)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"359172dd-4ad0-40ff-bc28-72507f682f2d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Temporary view is created using createOrReplaceTempView, for performing sql operations. Table name is given as params. \nsdf.createOrReplaceTempView(\"patients_details\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"35a8a092-42a1-4446-b268-aba746fb9e16"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##2. Descriptive Analytics"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7fdf74a3-4274-47b4-8da0-6fd8ac99ae22"}}},{"cell_type":"code","source":["# we can create new spark df by using sqlContext.sql() method by giving sal query as params.\ncardio_df = sqlContext.sql(\"select id, age from patients_details where Cardiomegaly = 1\").distinct()\ndisplay(cardio_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b325c93-8896-44de-b233-75c6e09059fc"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import udf\n\n#udf function is used to sort out data in age range vise.\nage_range = udf(lambda age: '1 < 20' if age < 20 else \n                   '20-30' if (age >= 20 and age < 30) else\n                   '30-40' if (age >= 30 and age < 40) else\n                   '40-50' if (age >= 40 and age < 50) else\n                   '50-60' if (age >= 50 and age < 60) else\n                   '60-70' if (age >= 60 and age < 70) else\n                   '70-80' if (age >= 70 and age < 80) else\n                    '80+'  if (age >= 80) else '')\n\ncardio_df = cardio_df.withColumn('age_range', age_range(cardio_df.age))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2ec81e86-698a-42a8-8278-d1ae3e38ecd5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\n#we can use display method provided by pyspark to visualize data \n#count according to age range is calculated using groupby followed with count function \ndisplay(cardio_df.groupBy(['age_range']).count().sort('age_range'))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d4bb9d87-bc38-47e7-9549-50e95b49fb80"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Alternative way to plot graph is to use matlib lib but the dataframe has to be converted to pandas. toPandas() method can be used to perfrom convertion. \ncardio_pdf = cardio_df.groupBy(['age_range']).count().sort('age_range').toPandas()\n\ncardio_pdf.plot(kind='bar', x='age_range', y='count', label='Cardiomegaly')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"da9a6cdb-a086-4b12-9d1a-10b467783625"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Similarly we can combine two or more dataframes in a single graph.\ninfiltration_df = sqlContext.sql(\"select id, age from patients_details where Infiltration = 1\").distinct()\npneumonia_df = sqlContext.sql(\"select id, age from patients_details where Pneumonia = 1\").distinct()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"660e5629-2a0e-4902-82b2-562fb5b05945"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##4.Data Visualisation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bb1eeab9-59f2-4f27-a1e8-ea1fc71c0a5e"}}},{"cell_type":"code","source":["infiltration_df = infiltration_df.withColumn('age_range', age_range(infiltration_df.age))\npneumonia_df = pneumonia_df.withColumn('age_range', age_range(pneumonia_df.age))\n\ninfiltration_pdf = infiltration_df.groupBy(['age_range']).count().sort('age_range').toPandas()\npneumonia_pdf = pneumonia_df.groupBy(['age_range']).count().sort('age_range').toPandas()\n\n# we will be able to plot multiple items against it\nax = plt.gca()\n\ncardio_pdf.plot(kind='line', x='age_range', y='count', label='Cardiomegaly', ax=ax , marker='o' )\ninfiltration_pdf.plot(kind='line', x='age_range', y='count', label='Infiltration', ax=ax , marker='*')\npneumonia_pdf.plot(kind='line', x='age_range', y='count', label='Pneumonia', ax=ax , marker='+' )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5e80f20-b1d9-4370-a996-3759adf0ef12"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["The graph incicates the comparison between three different diseases and thier occurance in relavance to their age group. We can clearly see that at in age range of 50 to 60 the number of patients are more. The line of each observation have a sligt increase in slope till age range 50-60 but later gradual decrease can be noticed."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82a80377-058f-4ae4-bdb4-9baf70bcb3e6"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"L00163516-EDA (1) (1)","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1890542581890438}},"nbformat":4,"nbformat_minor":0}
